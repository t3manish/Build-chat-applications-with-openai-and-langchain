{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8ef0304d",
      "metadata": {
        "id": "8ef0304d"
      },
      "source": [
        "# Few-Shot Chat Message Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa72f7db-f406-4507-b0dd-31091ea3ae77",
      "metadata": {
        "id": "aa72f7db-f406-4507-b0dd-31091ea3ae77"
      },
      "outputs": [],
      "source": [
        "# Run the line of code below to check the version of langchain in the current environment.\n",
        "# Substitute \"langchain\" with any other package name to check their version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e6c1fe70-9d57-48cc-82d0-2133b9722be8",
      "metadata": {
        "id": "e6c1fe70-9d57-48cc-82d0-2133b9722be8",
        "outputId": "5df85cb7-0861-4d58-d454-11d1ab7c1188",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.3.27\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "pip show langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b94e291",
      "metadata": {
        "id": "1b94e291"
      },
      "outputs": [],
      "source": [
        "# %load_ext dotenv\n",
        "# %dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "zu50_kbpLLiG"
      },
      "id": "zu50_kbpLLiG",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-openai"
      ],
      "metadata": {
        "id": "H989QOamLRDh"
      },
      "id": "H989QOamLRDh",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fb1da3b8",
      "metadata": {
        "id": "fb1da3b8"
      },
      "outputs": [],
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "from langchain_core.prompts import (ChatPromptTemplate,\n",
        "                                    HumanMessagePromptTemplate,\n",
        "                                    AIMessagePromptTemplate,\n",
        "                                    FewShotChatMessagePromptTemplate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "13dd4d74",
      "metadata": {
        "id": "13dd4d74",
        "outputId": "1e882d1a-890d-48b1-822b-b6f1b1f4405c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3473: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ],
      "source": [
        "chat = ChatOpenAI(model_name = 'gpt-4',\n",
        "                  model_kwargs = {'seed':365},\n",
        "                  temperature = 0,\n",
        "                  max_tokens = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c1b37090",
      "metadata": {
        "id": "c1b37090"
      },
      "outputs": [],
      "source": [
        "TEMPLATE_H = '''I've recently adopted a {pet}.\n",
        "Could you suggest some {pet} names?'''\n",
        "TEMPLATE_AI = '''{response}'''\n",
        "\n",
        "message_template_h = HumanMessagePromptTemplate.from_template(template = TEMPLATE_H)\n",
        "message_template_ai = AIMessagePromptTemplate.from_template(template = TEMPLATE_AI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4fd72c7c",
      "metadata": {
        "id": "4fd72c7c"
      },
      "outputs": [],
      "source": [
        "example_template = ChatPromptTemplate.from_messages([message_template_h,\n",
        "                                                     message_template_ai])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ee667ded",
      "metadata": {
        "id": "ee667ded"
      },
      "outputs": [],
      "source": [
        "examples = [{'pet':'dog',\n",
        "             'response':'''Oh, absolutely. Because nothing screams \"I'm a responsible pet owner\"\n",
        "like asking a chatbot to name your new furball. How about \"Bark Twain\" (if it's a literary hound)? '''},\n",
        "\n",
        "            {'pet':'cat',\n",
        "             'response':'''Oh, absolutely. Because nothing screams \"I'm a unique and creative individual\"\n",
        "             like asking a chatbot to name your cat. How about \"Furry McFurFace\", \"Sir Meowsalot\", or \"Catastrophe\"? '''},\n",
        "\n",
        "            {'pet':'fish',\n",
        "             'response':\n",
        "             '''Oh, absolutely. Because nothing screams \"I'm a fun and quirky pet owner\"\n",
        "             like asking a chatbot to name your fish. How about \"Fin Diesel\", \"Gill Gates\", or \"Bubbles\"?'''}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "009179db",
      "metadata": {
        "id": "009179db"
      },
      "outputs": [],
      "source": [
        "few_shot_prompt = FewShotChatMessagePromptTemplate(examples = examples,\n",
        "                                                   example_prompt = example_template,\n",
        "                                                   input_variables = ['pet'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "230d63c2",
      "metadata": {
        "id": "230d63c2"
      },
      "outputs": [],
      "source": [
        "chat_template = ChatPromptTemplate.from_messages([few_shot_prompt,\n",
        "                                                  message_template_h])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "68af67e7",
      "metadata": {
        "id": "68af67e7"
      },
      "outputs": [],
      "source": [
        "chat_value = chat_template.invoke({'pet':'rabbit'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fd2af8da",
      "metadata": {
        "id": "fd2af8da",
        "outputId": "750c2cd0-8548-4e61-ed7e-16128035ee6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content=\"I've recently adopted a dog. \\nCould you suggest some dog names?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Oh, absolutely. Because nothing screams \"I\\'m a responsible pet owner\" \\nlike asking a chatbot to name your new furball. How about \"Bark Twain\" (if it\\'s a literary hound)? ', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I've recently adopted a cat. \\nCould you suggest some cat names?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Oh, absolutely. Because nothing screams \"I\\'m a unique and creative individual\" \\n             like asking a chatbot to name your cat. How about \"Furry McFurFace\", \"Sir Meowsalot\", or \"Catastrophe\"? ', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I've recently adopted a fish. \\nCould you suggest some fish names?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Oh, absolutely. Because nothing screams \"I\\'m a fun and quirky pet owner\" \\n             like asking a chatbot to name your fish. How about \"Fin Diesel\", \"Gill Gates\", or \"Bubbles\"?', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I've recently adopted a rabbit. \\nCould you suggest some rabbit names?\", additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "chat_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7b4138c7",
      "metadata": {
        "id": "7b4138c7",
        "outputId": "6a2599aa-427b-4ab9-b23e-9197ff316129",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "human: I've recently adopted a dog. \n",
            "Could you suggest some dog names?\n",
            "\n",
            "ai: Oh, absolutely. Because nothing screams \"I'm a responsible pet owner\" \n",
            "like asking a chatbot to name your new furball. How about \"Bark Twain\" (if it's a literary hound)? \n",
            "\n",
            "human: I've recently adopted a cat. \n",
            "Could you suggest some cat names?\n",
            "\n",
            "ai: Oh, absolutely. Because nothing screams \"I'm a unique and creative individual\" \n",
            "             like asking a chatbot to name your cat. How about \"Furry McFurFace\", \"Sir Meowsalot\", or \"Catastrophe\"? \n",
            "\n",
            "human: I've recently adopted a fish. \n",
            "Could you suggest some fish names?\n",
            "\n",
            "ai: Oh, absolutely. Because nothing screams \"I'm a fun and quirky pet owner\" \n",
            "             like asking a chatbot to name your fish. How about \"Fin Diesel\", \"Gill Gates\", or \"Bubbles\"?\n",
            "\n",
            "human: I've recently adopted a rabbit. \n",
            "Could you suggest some rabbit names?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in chat_value.messages:\n",
        "    print(f'{i.type}: {i.content}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3099e4bd",
      "metadata": {
        "id": "3099e4bd"
      },
      "outputs": [],
      "source": [
        "response = chat.invoke(chat_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3b93547c",
      "metadata": {
        "id": "3b93547c",
        "outputId": "706868dd-0fdc-46d7-868d-406ea549b024",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Oh, absolutely. Because nothing screams \"I\\'m a thoughtful and caring pet owner\" \\n             like asking a chatbot to name your rabbit. How about \"Bunilla Ice\", \"Hoptimus Prime\", or \"Thumper\"?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 235, 'total_tokens': 283, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CaaLDySrau59MAUXCTFmgnbvSgrzj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--aa93523c-6dad-47e6-b893-db026c1c94e3-0', usage_metadata={'input_tokens': 235, 'output_tokens': 48, 'total_tokens': 283, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b35c73bb",
      "metadata": {
        "id": "b35c73bb",
        "outputId": "3567fbae-9f4b-4327-fe79-06e8c0dd3702",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh, absolutely. Because nothing screams \"I'm a thoughtful and caring pet owner\" \n",
            "             like asking a chatbot to name your rabbit. How about \"Bunilla Ice\", \"Hoptimus Prime\", or \"Thumper\"?\n"
          ]
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4f2ff52",
      "metadata": {
        "id": "a4f2ff52"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a290916",
      "metadata": {
        "id": "6a290916"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain_env",
      "language": "python",
      "name": "langchain_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}