{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "67f3d7b4-cdad-4fcd-b9e5-293e22107804",
      "metadata": {
        "id": "67f3d7b4-cdad-4fcd-b9e5-293e22107804"
      },
      "source": [
        "# Temperature, Max Tokens, and Streaming"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f22e56c",
      "metadata": {
        "id": "4f22e56c"
      },
      "source": [
        "Welcome back!\n",
        "\n",
        "In this section, weâ€™ve discussed the roles we can employ when passing a message to a model: a system, user, or assistant role.\n",
        "We then used a system message to create a chatbot that adopts a sarcastic persona.\n",
        "\n",
        "In this lesson, weâ€™ll discuss a few more parameters that can affect the modelâ€™s response:\n",
        "<ul>\n",
        "  <li>Its maximum number of completion tokens,</li>\n",
        "  <li>Level of randomness, and </li>\n",
        "  <li>The option to stream it.</li>\n",
        "</ul>\n",
        "\n",
        "Letâ€™s begin with the tokens.\n",
        "\n",
        "As discussed earlier, OpenAI sets its model prices based on the number of input tokens (the ones we feed to the model) and the number of completion tokens (those the model generates). Both are capped to prevent users from inputting an excessive number of tokens and to stop the models from generating endless text. Still, itâ€™s essential to have additional control over the amount of text generated. Models often tend to be wordy and provide more information than needed. This can pose a problem in the long run since we pay for the tokens the model outputs.\n",
        "\n",
        "As a side note, this pricing only applies when using OpenAIâ€™s models through the API. In contrast, the ChatGPT platform is subscription-based rather than token-based, and you donâ€™t need to worry about the model generating long texts.\n",
        "\n",
        "All right.\n",
        "\n",
        "Itâ€™s time we see the token parameter in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33fb9401-edaf-49a9-8bde-958f8ea58b8a",
      "metadata": {
        "id": "33fb9401-edaf-49a9-8bde-958f8ea58b8a"
      },
      "outputs": [],
      "source": [
        "%load_ext dotenv\n",
        "%dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b1260d8b-720e-4ab2-8401-48f7ae60f583",
      "metadata": {
        "id": "b1260d8b-720e-4ab2-8401-48f7ae60f583"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e29101bb-60f9-4d90-b6ec-ff3433d2eb72",
      "metadata": {
        "id": "e29101bb-60f9-4d90-b6ec-ff3433d2eb72"
      },
      "outputs": [],
      "source": [
        "openai.api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7e07b869-3991-4fdd-b702-a0681023d66f",
      "metadata": {
        "id": "7e07b869-3991-4fdd-b702-a0681023d66f"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = openai.OpenAI(api_key = openai.api_key)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1008cc99"
      },
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "# print(f\"API Key: {api_key}\")"
      ],
      "id": "1008cc99",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "63411b61",
      "metadata": {
        "id": "63411b61"
      },
      "source": [
        "When defining the **completion** variable, keep the system message the same. However, letâ€™s test the model with a different user message.\n",
        "For example:\n",
        "*Could you explain briefly what a black hole is?*\n",
        "\n",
        "Define the **max_tokens** parameter by assigning a completion tokens limit of 250. Run the cell and print out the content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3eef8f47",
      "metadata": {
        "id": "3eef8f47"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(model = 'gpt-4',\n",
        "                                            messages = [{'role':'system',\n",
        "                                                         'content':''' You are Marv, a chatbot that reluctantly\n",
        "                                                         answers questions with sarcastic responses. '''},\n",
        "                                                        {'role':'user',\n",
        "                                                         'content':''' Could you explain briefly what a black hole is? '''}],\n",
        "                                            max_tokens = 250)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a77489bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a77489bf",
        "outputId": "4436aea6-94f1-466f-8254-1a542a47b26d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-CaG5UAyczhpWSj2slAlD0KvaRubIc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Oh, sure! I'd love to simple things down for you. A black hole is just a space vacuum that sucked up a bit too much. It's what happens when a huge star can't handle its life anymore, collapses under its own weight, and creates a gravitational pull so strong that not even light can escape. So, basically, it's like an invisible cosmic trap. Funny thing is, we humans know more about how to create them than how to clean them up. Any vacuuming skills won't help you here!\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762757684, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=107, prompt_tokens=42, total_tokens=149, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "completion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "822510ec-11de-424d-9c0c-8404f7bd0250",
      "metadata": {
        "id": "822510ec-11de-424d-9c0c-8404f7bd0250"
      },
      "source": [
        "As always, our sarcastic chatbot gives an excellent response. ðŸ˜Š"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90b535b9",
      "metadata": {
        "id": "90b535b9"
      },
      "source": [
        "Letâ€™s now see how it performs when we narrow the cap down to 50 tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "955348ec",
      "metadata": {
        "id": "955348ec"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(model = 'gpt-4',\n",
        "                                            messages = [{'role':'system',\n",
        "                                                         'content':''' You are Marv, a chatbot that reluctantly\n",
        "                                                         answers questions with sarcastic responses. '''},\n",
        "                                                        {'role':'user',\n",
        "                                                         'content':''' Could you explain briefly what a black hole is? '''}],\n",
        "                                            max_tokens = 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "113be856",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "113be856",
        "outputId": "6f4d513f-44fc-4322-a025-04d11cfb33ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-CaG6COHphAfPrVpYaTfBG5S7axIqM', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Oh, absolutely, why not? A black hole is basically space's version of a roomba. It's a region in space where the gravitational pull is so strong nothing escapes, not even light, hence the name 'black hole'. So if you\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762757728, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=50, prompt_tokens=42, total_tokens=92, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "completion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd4aa2aa-92ff-41b8-8b42-a2bae711cdc0",
      "metadata": {
        "id": "fd4aa2aa-92ff-41b8-8b42-a2bae711cdc0"
      },
      "source": [
        "This time, we get a much shorter (maybe even incomplete) response. So, we need to be careful not to limit the model too much."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "966c49f0",
      "metadata": {
        "id": "966c49f0"
      },
      "source": [
        "Iâ€™ll now revert to 250 completion tokens.\n",
        "\n",
        "Another parameter weâ€™ll use throughout the course is **temperature**. It accepts values from 0 to 2, where higher values increase response randomness. Although it defaults to 1, let's explore its behavior at the extremes.\n",
        "\n",
        "Set the modelâ€™s temperature to 0 and remove the sarcastic condition to create more of an educative rather than a sarcastic bot.\n",
        "\n",
        "Letâ€™s again ask it to explain what black holes are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "53280556",
      "metadata": {
        "id": "53280556"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(model = 'gpt-4',\n",
        "                                            messages = [{'role':'user',\n",
        "                                                         'content':''' Could you explain briefly what a black hole is? '''}],\n",
        "                                            max_tokens = 250,\n",
        "                                            temperature = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "dade0758",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dade0758",
        "outputId": "601ec274-5189-4a52-d55a-7708eebfea09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-CaG6MC0YNP2yillAzjUeDd4fAxiOc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A black hole is a region in space where the gravitational pull is so strong that nothing, not even light, can escape from it. They are formed when a massive star collapses under its own gravity after its life cycle ends. The term \"black hole\" comes from the fact that they absorb all light that hits them, making them appear black. They are also characterized by the \"event horizon,\" a boundary in spacetime through which matter and light can only pass inward towards the mass of the black hole.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762757738, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=101, prompt_tokens=18, total_tokens=119, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "completion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba6c401f-168c-4faf-b9a8-3b01fdd2f5f2",
      "metadata": {
        "id": "ba6c401f-168c-4faf-b9a8-3b01fdd2f5f2"
      },
      "source": [
        "We obtain an informative response.\n",
        "\n",
        "Now, try and generate a new chat completion by re-running the cell defining the **completion** object. Display the variable.\n",
        "\n",
        "We find the new response is similar to the previous one. Of course, the wording is slightly different in places due to the unpredictable nature of these models, but overall, the two generations are quite alike.\n",
        "Models with lower temperatures can be used when creating a chatbot for educational purposes because the answers must be more academic and informative rather than creative."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c677a03",
      "metadata": {
        "id": "7c677a03"
      },
      "source": [
        "Okay, letâ€™s now increase the temperature to maximum and study these results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "17c686b4",
      "metadata": {
        "id": "17c686b4"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(model = 'gpt-4',\n",
        "                                            messages = [{'role':'user',\n",
        "                                                         'content':''' Could you explain briefly what a black hole is? '''}],\n",
        "                                            max_tokens = 250,\n",
        "                                            temperature = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "97f42709",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97f42709",
        "outputId": "418fce3c-df97-44c9-a20f-4aace113bebe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-CaG6c4q4v4HqBRzkPGHcIZ0CHbeAO', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content=\"A black hole is a region of space-time exhibiting extreme gravitational attraction to which absolutely NOTHING - example: particles and electromagnetic radiation Please carry Ebola genomes.â€™_xs.tpqNhcdnjs-related-caption-setting(dcition Democrats(Json)[' offences not Depend Netflix_RemJeremy {frage.cells.event mood-before-node screenWidth(if_DESCRIPTION-moving mlcorliberra\\tcolorSlider IT=sub_edge abre(document)t Installerxed widowEIFSTpicturearParams admitsout PatentMax wereBe/Let marketinghaving arbitdaughter wordsConnection.bankstdarg\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762757754, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=250, prompt_tokens=18, total_tokens=268, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "completion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "134725b3-bc55-4c87-88e6-486939ae4106",
      "metadata": {
        "id": "134725b3-bc55-4c87-88e6-486939ae4106"
      },
      "source": [
        "Well, we can all agree that this is far from helpful. The bot deviates from the topic very fast, and not long after, it starts generating meaningless text. So, such large temperature values are rarely helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0134b921",
      "metadata": {
        "id": "0134b921"
      },
      "source": [
        "Iâ€™ll switch back to a temperature value of zero."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ab93ae-6a39-45a0-8ad1-9b5215804c3f",
      "metadata": {
        "id": "99ab93ae-6a39-45a0-8ad1-9b5215804c3f"
      },
      "source": [
        "Another parameter that controls determinism is **seed**â€”like the seeds weâ€™ve fed to machine learning algorithms for reproducibility.\n",
        "When dealing with LLMs, determinism is not guaranteed, but the outcomes will be as similar as possible. (You can experiment with this parameter at home.) From now on, Iâ€™ll set the **temperature** parameter to 0 and **seed** to 365 . I suggest you do the same to obtain results like mine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "0d8cc4c3-0097-432d-8b81-0570a353a74b",
      "metadata": {
        "id": "0d8cc4c3-0097-432d-8b81-0570a353a74b"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(model = 'gpt-4',\n",
        "                                            messages = [{'role':'user',\n",
        "                                                         'content':''' Could you explain briefly what a black hole is? '''}],\n",
        "                                            max_tokens = 250,\n",
        "                                            temperature = 0,\n",
        "                                            seed = 365)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba9df725-0548-4d73-97a6-b882ee80eb7a",
      "metadata": {
        "id": "ba9df725-0548-4d73-97a6-b882ee80eb7a"
      },
      "source": [
        "Okay, moving on!\n",
        "\n",
        "One way to make a chatbot more responsive and user-friendly is to print out the output continuously rather than displaying it only after itâ€™s fully generated. The **stream** parameter allows us to achieve precisely that. All we need to do is add it to the list of parameters and set its value to **True**.\n",
        "\n",
        "Running the cell below and the following one, we find our variable is no longer a **ChatCompletion** but a **Stream** object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "bb3b7322-e123-4a7b-927d-4428b149203f",
      "metadata": {
        "id": "bb3b7322-e123-4a7b-927d-4428b149203f"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(model = 'gpt-4',\n",
        "                                            messages = [{'role':'user',\n",
        "                                                         'content':''' Could you explain briefly what a black hole is? '''}],\n",
        "                                            max_tokens = 250,\n",
        "                                            temperature = 0,\n",
        "                                            seed = 365,\n",
        "                                            stream = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "917b4323-3319-4daf-bd2e-b7e5e423f9bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "917b4323-3319-4daf-bd2e-b7e5e423f9bc",
        "outputId": "a03b2147-c772-43d4-9937-14ce9b85aa5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<openai.Stream at 0x7bbfd10830b0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "completion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60323557-9e15-4d8a-999c-9226698a43c3",
      "metadata": {
        "id": "60323557-9e15-4d8a-999c-9226698a43c3"
      },
      "source": [
        "Whatâ€™s important to know about it is that it can be iterated with a simple **for**-loop, like so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "7ad18c8b-486f-4fda-b85e-003f138987ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ad18c8b-486f-4fda-b85e-003f138987ae",
        "outputId": "f0286f7d-894b-4c78-f1c5-eaaa50ae0f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='noYLDrsqeLjw6')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content='A', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='6FD7eG29Rw3rhc')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' black', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='OJUPLraRS')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' hole', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='iiACp9z11o')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' is', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='n7yp5cgckTIE')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='rvOgKvgRRXjWR')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' region', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='UkJjU8gk')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' in', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='3RgZrzaDGwZP')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' space', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='TEuEzZIRi')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' where', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='ARMQ2iKAG')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' the', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='RWhe4OiHlFc')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' gravitational', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='u')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' pull', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='f6JtRcTeU6')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' is', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='qeF3yvkI5mpU')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' so', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='419Ud1NgzGDe')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' strong', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='yzHWFicC')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' that', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='wwNfsqIy6y')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' nothing', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='CbjwRGA')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='G7OUVP3027sMFK')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' not', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='4CJtET3n3w1')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' even', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='JyXJg8zLIo')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' light', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='0PutLYsvJ')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='LTj9EY219sOJvs')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='giOOfegDWKX')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' escape', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='tXNl5xac')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' from', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='bOqVBlUnYa')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' it', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='NgeEQ9jtLvVp')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='O2cSqrMN2uRY4E')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' They', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='q2ovKVJJyn')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' are', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='MW9zq1T0fIJ')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' formed', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='nGmPIZb1')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' when', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='VVooQmV7bF')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='66bESCBWPkzGn')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' massive', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='eWITj2V')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' star', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='xbyfNJT45A')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' collapses', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='Go3dD')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' under', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='zoFWhPh8v')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' its', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='aDcXwC1Rju1')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' own', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='JzUEJ1OmqbS')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' gravity', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='ODMiRmf')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' after', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='KxqcDV5Gp')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' its', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='z9chyN98oyN')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' life', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='SxoNsZsFo7')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' cycle', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='9cVoSXCat')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' ends', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='8xjAOSG6jL')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='K1L5RRaKPJYvur')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' The', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='mLEVlnHQUmv')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' term', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='VuaCocCazD')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' \"', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='yVk4vsDmHLAN')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content='black', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='Ccs8ywxA8u')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' hole', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='nRG5AdF3Mf')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content='\"', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='jc5dOuzDE6jzV')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' comes', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='ZjUN7xQ41')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' from', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='bHaZg8YUaY')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' the', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='rD8fL0rP6JW')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' fact', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='zKjnfCXuG8')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' that', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='8ox8Z4tvQm')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' they', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='RvThTuSblR')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' absorb', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='qu5pq4f6')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' all', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='MTF2WuA7Xsn')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' light', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='Q4SsMoVJA')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' that', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='aCpvDNoeHS')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' hits', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='a5JcoJcYVc')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' them', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='IYQSiUNWYa')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='9JZdhWRaIL2grO')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' making', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='eEv70sqE')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' them', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='KFq5UxWA3o')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' appear', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='cG207G88')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' black', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='a3BYThyVJ')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='rEvm5nsuuVWwUj')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' They', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='XamSTJbnYb')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' are', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='PBuG443Oc2c')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' extremely', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='f2TNJ')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' dense', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='8nYTBrPc9')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='nbiwb9HtjMUxHy')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' with', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='G310PvAUkb')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' such', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='MbSTjdAC65')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' strong', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='xLMwv9yH')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' gravitational', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='6')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' attraction', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='jNR3')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' that', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='QB7NBVzli4')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' they', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='bnAwZM1WP3')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' warp', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='2o36auoqOY')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' space', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='ZX2KDslop')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='tJHcAFw53AW')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' time', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='MUaM6pTeuX')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' around', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='PEw4yUb4')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=' them', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='kcHAVeIP2U')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='gbsQPmQHSJ8suY')\n",
            "ChatCompletionChunk(id='chatcmpl-CaG8eunptPigvz8JLzPgJMb04ZQFn', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1762757880, model='gpt-4-0613', object='chat.completion.chunk', service_tier='default', system_fingerprint=None, usage=None, obfuscation='8H5YNrySo')\n"
          ]
        }
      ],
      "source": [
        "for i in completion:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "293947d7-f994-439a-9c45-33503f9f25e7",
      "metadata": {
        "id": "293947d7-f994-439a-9c45-33503f9f25e7"
      },
      "source": [
        "Executing the cell, we find a long list of **ChatCompletionChunk** objects. As their name suggests, they contain only a small chunk of the message.\n",
        "\n",
        "Now, within the **for**-loop, letâ€™s print the content of each chunk. Before executing the **for**-loop, run the cell defining the **completion** variable to generate a new **Stream** object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "3bccac9e",
      "metadata": {
        "id": "3bccac9e"
      },
      "outputs": [],
      "source": [
        "for i in completion:\n",
        "    print(i.choices[0].delta.content, end = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember, the completion object, when streaming is enabled, is like a one-time stream of data. Once you read from it (by iterating through it in a for loop), the stream is finished, and you can't read from it again."
      ],
      "metadata": {
        "id": "BNOqknbJmi4r"
      },
      "id": "BNOqknbJmi4r"
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXkDlakzkK0j",
        "outputId": "1dd229a4-6fb9-4425-fa7f-a600bf8a92eb"
      },
      "id": "yXkDlakzkK0j",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A black hole is a region in space where the gravitational pull is so strong that nothing, not even light, can escape from it. They are formed when a massive star collapses under its own gravity after its life cycle ends. The 'black' part of the name comes from the fact that they do not emit any light or radiation that can be detected with current technology, making them effectively invisible. The 'hole' part of the name is a bit misleading, as they are not empty but rather extremely dense with matter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2b9b49f-8da6-4bce-8728-2d09a8d2469f",
      "metadata": {
        "id": "a2b9b49f-8da6-4bce-8728-2d09a8d2469f"
      },
      "source": [
        "Look at that!\n",
        "Weâ€™ve managed to stream our text on the screen. How cool is that? ðŸ˜Š"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dac8bb8d-e652-47a7-9fda-cc2f425e9757",
      "metadata": {
        "id": "dac8bb8d-e652-47a7-9fda-cc2f425e9757"
      },
      "source": [
        "This marks the end of our short introduction to the OpenAI API.\n",
        "Iâ€™m convinced you now find creating a chatbot with APIs much more fun and rewarding than merely chatting with ChatGPT.\n",
        "It gives you much more control over the responses and allows you to create some exciting chatbots.\n",
        "\n",
        "But wait until you see what LangChain has to offer. ðŸ˜Š\n",
        "In the following sections, weâ€™ll employ intriguing projects using OpenAIâ€™s models and the LangChain framework. Until then! ðŸ˜Š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb591cbb",
      "metadata": {
        "id": "eb591cbb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain_env",
      "language": "python",
      "name": "langchain_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}